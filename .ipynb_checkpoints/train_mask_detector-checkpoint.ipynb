{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "[INFO] compiling model...\n",
      "[INFO] training head...\n",
      "Epoch 1/20\n",
      "20/34 [================>.............] - ETA: 14s - loss: -0.9626 - accuracy: 0.8998"
     ]
    }
   ],
   "source": [
    "# USAGE\n",
    "# python train_mask_detector.py --dataset dataset\n",
    "\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "INIT_LR = 1e-4#taux d'apprentissage initial\n",
    "EPOCHS = 20#le nombre d'époques d'entraînement\n",
    "BS = 32#taille du lot\n",
    "\n",
    "#Récupération de tous les imagePaths de l'ensemble de données \n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(\"dataset\"))\n",
    "data = []#Initialisation des listes de données et d'étiquettes\n",
    "labels = []#et d'étiquettes\n",
    "\n",
    "#charger les chemins des images dataset et les labels with et without mask \n",
    "for imagePath in imagePaths:\n",
    "\tlabel = imagePath.split(os.path.sep) #La méthode os.path.split () en Python est utilisée pour diviser le nom du chemin en une tertaire tête milieu et queue. \n",
    "\tlabel = imagePath.split(os.path.sep)[-2]#ne prendre que with ou without mask     \n",
    "\t# load the input image (224x224) and preprocess it\n",
    "\timage = load_img(imagePath, target_size=(224, 224))#resize à 224x224\n",
    "\n",
    "\timage = img_to_array(image)#la conversion au format de matrice \n",
    "\n",
    "\timage = preprocess_input(image)# la mise à l'échelle des intensités de pixels de l'image d'entrée à la plage [-1, 1] (via la fonction de commodité preprocess_input)\n",
    "\t# Ajouter chaque image prétraité à la variable data\n",
    "\tdata.append(image)\n",
    "\tlabels.append(label)\n",
    " \n",
    "\n",
    "\t# convertir au format numpy\n",
    "data = np.array(data, dtype=\"float32\")#S'assurer que nos données d'entraînement sont au format de tableau NumPy\n",
    "labels = np.array(labels)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)#transformer en binaire(0.1) 0 with and 1 without mask\n",
    "labels = to_categorical(labels)#transformer en catégorie puisque on a with and without mask 1 (2 catégorie) liste binaire avec 1 dans l'endroit oùil faut le mettre \n",
    "labels=np.argmax(labels, axis=1)\n",
    "# répartir nos données entre 20% de tests et 80% d'entrainement\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.20, random_state=42)\n",
    "#Il y a une classe dans la bibliothèque qui est, à juste titre, nommée 'train_test_split. «Grâce à cela, nous pouvons facilement diviser l'ensemble de données en ensembles de données d'entraînement et de test dans diverses proportions. ... test_size - Ce paramètre décide de la taille des données qui doivent être divisées en tant que jeu de données de test. Ceci est donné sous forme de fraction.\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,#rotation\n",
    "\tzoom_range=0.15,#zoom\n",
    "\twidth_shift_range=0.2,#contrôle la largeur du réseau. \n",
    "    height_shift_range=0.2,#contrôle la hauteur du réseau.\n",
    "\tshear_range=0.15,#cisaillement\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "#Ceci est connu comme le multiplicateur de largeur dans le document MobileNet. - Si alpha <1,0, diminue proportionnellement le nombre de filtres dans chaque couche. - Si alpha> 1.0, augmente proportionnellement le nombre de filtres dans chaque couche. - Si alpha = 1, le nombre par défaut de filtres du papier est utilisé à chaque couche.\n",
    "# charger MobileNetV2 \n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "#construire la tête du modèle qui sera placé au dessus du modèle de base\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)# 1ère couche /taille de l'image\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)# 128 fonctions qui en les combinant, et si on génère tous les pixels du viasage  génère une valeur \n",
    "#la fonction d'activation qui renvoie une valeur supérieure à 0\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)#nombre de types de visages différents(with or without mask)\n",
    "#la fonction d'activation softmax met la plus grande probabilité des 2 cases 1 et l'autre à 0\n",
    "#Le réglage fin est une stratégie que je recommande presque toujours pour établir un modèle de référence tout en gagnant un temps considérable.\n",
    "# place the head FC model on top of the base model (this will become\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "# arrêter la mise à jour du modèle\n",
    "for layer in baseModel.layers:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "# compiler notre model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)#compiler le modèle avec l'optimiseur adam\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=\"accuracy\")\n",
    "#ce compilateur prend 2 valeurs l'optimiseur et l'erreur\n",
    "#si l'alogorithme prédit une valeur alors la fonction d'erreur nous donne la médiocrité du modèle grâce à la fonction d'érreure\n",
    "#l'algorithme nous utilisera la fonction d'optimisation pour donner une autre estimation\n",
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BS,\n",
    "\tepochs=20)\n",
    "#il repètra ca 20 fois selon le nombre de d'epochs(faire une prévision, calculer sa précision, utiliser l'optimisation pour calculer la prévision ect)\n",
    "#prédiction du modèle\n",
    "print(\"[INFO] evaluating network...\")\n",
    "#prédictions pour de nouvelles images\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n",
    "# trouver l'index du label avec la plus grande probabilité\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "#enregistrer le modèle\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"mask_detector.model\", save_format=\"h5\")\n",
    "\n",
    "# représentation graphiques de la précision et des erreurs  du modèle \n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
